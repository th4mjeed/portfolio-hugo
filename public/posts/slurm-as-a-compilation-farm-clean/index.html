<!DOCTYPE html>
<html lang="en" dir="auto" data-theme="dark">

<head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=45935&amp;path=livereload" data-no-instant defer></script><meta charset="utf-8">
<meta http-equiv="X-UA-Compatible" content="IE=edge">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<meta name="robots" content="noindex, nofollow">
<title>SLURM as a Compilation Farm | Thamjeed</title>
<meta name="keywords" content="">
<meta name="description" content="

Note: ðŸ“¢ This document is based on my understanding of SLURM and is in no way a detailed guide covering every single topic. Take this as a practical guide from a noobâ€™s perspective diving into it.
Introduction:
This guide is designed to help you effectively use the SLURM scheduler on Rocky Linux 9.5 server. The Server allows you to run computational jobs using both interactive and non-interactive modes. The goal here is to make a compilation farm, although this guide specifically focuses on compiling the Linux kernel, one should note that this may also be used to compile any other tool given that the prerequisites and dependencies are known.">
<meta name="author" content="">
<link rel="canonical" href="http://localhost:45935/posts/slurm-as-a-compilation-farm-clean/">
<link crossorigin="anonymous" href="/assets/css/stylesheet.a5781257de4197b8e3d54346acdf1dd55a9ba4cb91dcace192fc1baf228c08b5.css" integrity="sha256-pXgSV95Bl7jj1UNGrN8d1VqbpMuR3KzhkvwbryKMCLU=" rel="preload stylesheet" as="style">
<link rel="icon" href="http://localhost:45935/favicon.ico">
<link rel="icon" type="image/png" sizes="16x16" href="http://localhost:45935/favicon-16x16.png">
<link rel="icon" type="image/png" sizes="32x32" href="http://localhost:45935/favicon-32x32.png">
<link rel="apple-touch-icon" href="http://localhost:45935/apple-touch-icon.png">
<link rel="mask-icon" href="http://localhost:45935/safari-pinned-tab.svg">
<meta name="theme-color" content="#2e2e33">
<meta name="msapplication-TileColor" content="#2e2e33">
<link rel="alternate" hreflang="en" href="http://localhost:45935/posts/slurm-as-a-compilation-farm-clean/">
<noscript>
    <style>
        #theme-toggle,
        .top-link {
            display: none;
        }

    </style>
</noscript>
</head>
<body id="top">
    <header class="header">
    <nav class="nav">
        <div class="logo">
            <a href="http://localhost:45935/" accesskey="h" title="Thamjeed (Alt + H)">Thamjeed</a>
            <div class="logo-switches">
            </div>
        </div>
        <ul id="menu">
            <li>
                <a href="http://localhost:45935/posts/" title="Blog">
                    <span>Blog</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:45935/projects/" title="Projects">
                    <span>Projects</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:45935/about/" title="About">
                    <span>About</span>
                </a>
            </li>
            <li>
                <a href="http://localhost:45935/search/" title="Search (Alt &#43; /)" accesskey=/>
                    <span>Search</span>
                </a>
            </li>
        </ul>
    </nav>
</header>
<main class="main">

<article class="post-single">
  <header class="post-header">
    
    <h1 class="post-title entry-hint-parent">
      SLURM as a Compilation Farm
    </h1>
    <div class="post-meta"><span title='2025-11-06 00:00:00 +0000 UTC'>November 6, 2025</span>

</div>
  </header> 
  <div class="post-content"><hr>
<blockquote>
<p><strong>Note:</strong> ðŸ“¢ This document is based on my understanding of SLURM and is in no way a detailed guide covering every single topic. Take this as a practical guide from a noobâ€™s perspective diving into it.</p></blockquote>
<h2 id="introduction"><strong>Introduction:</strong><a hidden class="anchor" aria-hidden="true" href="#introduction">#</a></h2>
<p>This guide is designed to help you effectively use the SLURM scheduler on Rocky Linux 9.5 server. The Server allows you to run computational jobs using both interactive and non-interactive modes. The goal here is to make a compilation farm, although this guide specifically focuses on compiling the Linux kernel, one should note that this may also be used to compile any other tool given that the prerequisites and dependencies are known.</p>
<h2 id="lab-infrastructure"><strong>Lab Infrastructure:</strong><a hidden class="anchor" aria-hidden="true" href="#lab-infrastructure">#</a></h2>
<p>The following are all on VMware ESXI</p>
<ol>
<li>
<p><strong>Master:</strong></p>
<ul>
<li>CPUs 4</li>
<li>Memory 4 GB</li>
<li>Hard disk 20 GB</li>
<li>Hostname: master</li>
</ul>
</li>
<li>
<p><strong>Node 1:</strong></p>
<ul>
<li>CPUs 4</li>
<li>Memory 4 GB</li>
<li>Hard disk 40 GB</li>
<li>Hostname: node1</li>
</ul>
</li>
<li>
<p><strong>Node 2:</strong></p>
<ul>
<li>CPUs 8</li>
<li>Memory 8 GB</li>
<li>Hard disk 40 GB</li>
<li>Hostname: node2</li>
</ul>
</li>
<li>
<p><strong>Network File Storage</strong></p>
<ul>
<li>Since compiling creates dozens of files, at least 30 GB is required for a successful compilation.</li>
<li>Used the existing testing server assigned to me.</li>
<li>NFS share path located in <strong>/mnt/slrum_share</strong></li>
</ul>
</li>
</ol>
<p>Every instance has Rocky Linux 9.5 installed with SSH, root login and defined IP of all 4 nodes in the <code>/etc/hosts</code> file.</p>
<p>The Architecture diagram looks like this:</p>
<figure>
    <img loading="lazy" src="/static/images/slurm-as-a-compilation-farm/SLUM_arch.drawio.png"
         alt="SLURM Architecture Diagram"/> 
</figure>

<h2 id="chapter-1-the-installation"><strong>Chapter 1: The installation:</strong><a hidden class="anchor" aria-hidden="true" href="#chapter-1-the-installation">#</a></h2>
<ol>
<li>
<p><strong>Install and configure dependencies</strong></p>
<p>Installation of slurm requires EPEL repo to be installed across all instances, install and enable it via:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>dnf config-manager --set-enabled crb
</span></span><span style="display:flex;"><span>dnf install epel-release
</span></span><span style="display:flex;"><span>sudo dnf groupinstall <span style="color:#e6db74">&#34;Development Tools&#34;</span>
</span></span><span style="display:flex;"><span>sudo dnf install munge munge-devel rpm-build rpmdevtools python3 gcc make openssl-devel pam-devel</span></span></code></pre></div>
<p>MUNGE is an authentication mechanism for secure communication between Slurm components. Configure it on all instances using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo useradd munge
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/munge /var/log/munge /var/run/munge
</span></span><span style="display:flex;"><span>sudo chown munge:munge /usr/local/var/run/munge
</span></span><span style="display:flex;"><span>sudo chmod <span style="color:#ae81ff">0755</span> /usr/local/var/run/munge</span></span></code></pre></div>
<p>On Master:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo /usr/sbin/create-munge-key
</span></span><span style="display:flex;"><span>sudo chown munge:munge /etc/munge/munge.key
</span></span><span style="display:flex;"><span>sudo chmod <span style="color:#ae81ff">0400</span> /etc/munge/munge.key</span></span></code></pre></div>
<p>Copy the key to both nodes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>scp /etc/munge/munge.key root@node1:/etc/munge/
</span></span><span style="display:flex;"><span>scp /etc/munge/munge.key root@node2:/etc/munge/</span></span></code></pre></div>
<p>Start and enable the service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable --now munge</span></span></code></pre></div>
</li>
<li>
<p><strong>Installation of SLURM</strong></p>
<p>Slurm is available in the EPEL repo. Install on all 3 instances:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install slurm slurm-slurmd slurm-slurmctld slurm-perlapi</span></span></code></pre></div>
<p>If by any chance packages are not available, download tar file from <a href="https://www.schedmd.com/download-slurm/">SchedMD Downloads</a>, extract, compile, and install using:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>make -j<span style="color:#66d9ef">$(</span>nproc<span style="color:#66d9ef">)</span>
</span></span><span style="display:flex;"><span>sudo make install</span></span></code></pre></div>
</li>
</ol>
<h2 id="chapter-2-the-configuration"><strong>Chapter 2: The Configuration:</strong><a hidden class="anchor" aria-hidden="true" href="#chapter-2-the-configuration">#</a></h2>
<ol>
<li>
<p><strong>Slurm configuration</strong></p>
<p>On all 3 instances:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo useradd slurm
</span></span><span style="display:flex;"><span>sudo mkdir -p /etc/slurm /var/spool/slurmctld /var/spool/slurmd /var/log/slurm
</span></span><span style="display:flex;"><span>sudo chown slurm:slurm /var/spool/slurmctld /var/spool/slurmd /var/log/slurm</span></span></code></pre></div>
<p>Edit the configuration on master:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo nano /etc/slurm/slurm.conf</span></span></code></pre></div>
<p>Ensure the following key lines are present and correctly configured:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-text" data-lang="text"><span style="display:flex;"><span>ClusterName=debug
</span></span><span style="display:flex;"><span>SlurmUser=slurm
</span></span><span style="display:flex;"><span>ControlMachine=slurm-master
</span></span><span style="display:flex;"><span>SlurmctldPort=6817
</span></span><span style="display:flex;"><span>SlurmdPort=6818
</span></span><span style="display:flex;"><span>AuthType=auth/munge
</span></span><span style="display:flex;"><span>StateSaveLocation=/var/spool/slurmctld
</span></span><span style="display:flex;"><span>SlurmdSpoolDir=/var/spool/slurmd
</span></span><span style="display:flex;"><span>SwitchType=switch/none
</span></span><span style="display:flex;"><span>MpiDefault=none
</span></span><span style="display:flex;"><span>SlurmctldPidFile=/var/run/slurmctld.pid
</span></span><span style="display:flex;"><span>SlurmdPidFile=/var/run/slurmd.pid
</span></span><span style="display:flex;"><span>ProctrackType=proctrack/pgid
</span></span><span style="display:flex;"><span>ReturnToService=1
</span></span><span style="display:flex;"><span>SchedulerType=sched/backfill
</span></span><span style="display:flex;"><span>SlurmctldTimeout=300
</span></span><span style="display:flex;"><span>SlurmdTimeout=30
</span></span><span style="display:flex;"><span>NodeName=node1 CPUs=4 RealMemory=3657 State=UNKNOWN
</span></span><span style="display:flex;"><span>NodeName=node2 CPUs=8 RealMemory=7682 State=UNKNOWN
</span></span><span style="display:flex;"><span>PartitionName=debug Nodes=node[1-2] Default=YES MaxTime=INFINITE State=UP</span></span></code></pre></div>
<p>Copy configuration to nodes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>scp /etc/slurm/slurm.conf root@node1:/etc/slurm/slurm.conf
</span></span><span style="display:flex;"><span>scp /etc/slurm/slurm.conf root@node2:/etc/slurm/slurm.conf</span></span></code></pre></div>
<p>Start and enable services:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo systemctl enable --now slurmctld
</span></span><span style="display:flex;"><span>sudo systemctl enable --now slurmd</span></span></code></pre></div>
</li>
<li>
<p><strong>Firewall Configuration:</strong></p>
<p>Open required ports:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>6817/tcp
</span></span><span style="display:flex;"><span>sudo firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>6818/tcp
</span></span><span style="display:flex;"><span>sudo firewall-cmd --permanent --add-port<span style="color:#f92672">=</span>6819/tcp
</span></span><span style="display:flex;"><span>sudo firewall-cmd --reload</span></span></code></pre></div>
</li>
</ol>
<h2 id="chapter-3-testing-and-introduction-to-the-commands"><strong>Chapter 3: Testing and Introduction to the commands:</strong><a hidden class="anchor" aria-hidden="true" href="#chapter-3-testing-and-introduction-to-the-commands">#</a></h2>
<p><strong>(While this is a short guide on the commands and its flags, you could always use man pages to understand it more deeply)</strong></p>
<ol>
<li>
<p><code>sinfo</code>:</p>
<p>Displays node and partition information:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sinfo</span></span></code></pre></div>
</li>
<li>
<p><code>srun</code>:</p>
<p>Runs commands interactively on compute nodes:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>srun -N2 -n2 nproc</span></span></code></pre></div>
</li>
<li>
<p><code>sbatch</code>:</p>
<p>Submits a job script:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sbatch testjob.sh</span></span></code></pre></div>
</li>
<li>
<p><code>squeue</code>:</p>
<p>Displays details of currently running jobs:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>squeue</span></span></code></pre></div>
</li>
<li>
<p><code>scancel</code>:</p>
<p>Cancels a submitted job:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>scancel <span style="color:#ae81ff">1</span></span></span></code></pre></div>
</li>
<li>
<p><code>scontrol</code>:</p>
<p>Displays detailed job and node information:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>scontrol show job <span style="color:#ae81ff">1</span></span></span></code></pre></div>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>scontrol show partition</span></span></code></pre></div>
</li>
</ol>
<h2 id="chapter-4-setting-up-the-nfs-storage"><strong>Chapter 4: Setting up the NFS storage.</strong><a hidden class="anchor" aria-hidden="true" href="#chapter-4-setting-up-the-nfs-storage">#</a></h2>
<p>It is a good idea to have shared storage for SLURM. Install <code>nfs-utils</code>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo dnf install nfs-utils</span></span></code></pre></div>
<p><strong>On the NFS server:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>mkdir /srv/slurm_share
</span></span><span style="display:flex;"><span>nano /etc/exports</span></span></code></pre></div>
<p>Add the following line:</p>
<pre tabindex="0"><code>/srv/slurm_share 10.10.40.0/24(rw,sync,no_subtree_check,no_root_squash)
</code></pre><p>Open necessary ports:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>firewall-cmd --permanent --add-service<span style="color:#f92672">=</span>rpc-bind
</span></span><span style="display:flex;"><span>firewall-cmd --permanent --add-port<span style="color:#f92672">={</span>5555/tcp,5555/udp,6666/tcp,6666/udp<span style="color:#f92672">}</span>
</span></span><span style="display:flex;"><span>firewall-cmd --reload</span></span></code></pre></div>
<p>Export and enable the service:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>exportfs -v
</span></span><span style="display:flex;"><span>systemctl enable --now nfs-server</span></span></code></pre></div>
<p><strong>On the master and compute nodes:</strong></p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>sudo mkdir /mnt/slurm_share</span></span></code></pre></div>
<p>Add the mount in <code>/etc/fstab</code>:</p>
<pre tabindex="0"><code>10.10.40.0:/srv/slurm_share /mnt/slurm_share nfs defaults 0 0
</code></pre><p>Reboot machines and verify the share mounts properly.</p>
<h2 id="chapter-5-setting-up-the-compilebuild-environment"><strong>Chapter 5: Setting up the Compile/Build Environment</strong><a hidden class="anchor" aria-hidden="true" href="#chapter-5-setting-up-the-compilebuild-environment">#</a></h2>
<p>Install kernel build dependencies:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>srun -n2 -N2 sudo dnf groupinstall <span style="color:#e6db74">&#34;Development Tools&#34;</span> -y <span style="color:#f92672">&amp;&amp;</span> sudo dnf install ncurses-devel bison flex elfutils-libelf-devel openssl-devel wget bc dwarves -y</span></span></code></pre></div>
<p>Download the Linux kernel source from <a href="https://kernel.org">kernel.org</a>:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>wget <span style="color:#f92672">[</span>https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.14.8.tar.xz<span style="color:#f92672">](</span>https://cdn.kernel.org/pub/linux/kernel/v6.x/linux-6.14.8.tar.xz<span style="color:#f92672">)</span>
</span></span><span style="display:flex;"><span>tar xvf linux-6.14.8.tar.xz</span></span></code></pre></div>
<p>Define architecture-specific config:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span>make defconfig</span></span></code></pre></div>
<p>Create <code>compile_kernel.sh</code> on the shared directory:</p>
<div class="highlight"><pre tabindex="0" style="color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4;"><code class="language-bash" data-lang="bash"><span style="display:flex;"><span><span style="color:#75715e">#!/bin/bash
</span></span></span><span style="display:flex;"><span><span style="color:#75715e"></span><span style="color:#75715e">#SBATCH --job-name=kernel_build</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --output=kernel_build_%j.out</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --error=kernel_build_%j.err</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --time=03:00:00</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --nodes=1</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --cpus-per-task=8</span>
</span></span><span style="display:flex;"><span><span style="color:#75715e">#SBATCH --mem=8G</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>KERNEL_SOURCE_PATH<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;/mnt/slurm_share/linux-6.8.9&#34;</span>
</span></span><span style="display:flex;"><span>BUILD_OUTPUT_DIR<span style="color:#f92672">=</span><span style="color:#e6db74">&#34;/mnt/slurm_share/kernel_builds/</span><span style="color:#e6db74">${</span>SLURM_JOB_ID<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>mkdir -p <span style="color:#e6db74">&#34;</span>$BUILD_OUTPUT_DIR<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>cd <span style="color:#e6db74">&#34;</span>$KERNEL_SOURCE_PATH<span style="color:#e6db74">&#34;</span>
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span>NUM_MAKE_JOBS<span style="color:#f92672">=</span><span style="color:#e6db74">${</span>SLURM_CPUS_PER_TASK<span style="color:#e6db74">}</span>
</span></span><span style="display:flex;"><span>make -j<span style="color:#e6db74">&#34;</span><span style="color:#e6db74">${</span>NUM_MAKE_JOBS<span style="color:#e6db74">}</span><span style="color:#e6db74">&#34;</span> ARCH<span style="color:#f92672">=</span>x86_64 Image modules dtbs
</span></span><span style="display:flex;"><span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">if</span> <span style="color:#f92672">[</span> $? -eq <span style="color:#ae81ff">0</span> <span style="color:#f92672">]</span>; <span style="color:#66d9ef">then</span>
</span></span><span style="display:flex;"><span>cp <span style="color:#e6db74">&#34;</span>$KERNEL_SOURCE_PATH<span style="color:#e6db74">/arch/x86/boot/bzImage&#34;</span> <span style="color:#e6db74">&#34;</span>$BUILD_OUTPUT_DIR<span style="color:#e6db74">/&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">else</span>
</span></span><span style="display:flex;"><span>echo <span style="color:#e6db74">&#34;Kernel compilation failed.&#34;</span>
</span></span><span style="display:flex;"><span><span style="color:#66d9ef">fi</span></span></span></code></pre></div>


  </div>

  <footer class="post-footer">
    <ul class="post-tags">
    </ul>
  </footer>
</article>
    </main>
    
<footer class="footer">
        <span>&copy; 2025 <a href="http://localhost:45935/">Thamjeed</a></span> Â· 

    <span>
        Powered by
        <a href="https://gohugo.io/" rel="noopener noreferrer" target="_blank">Hugo</a> &
        <a href="https://github.com/adityatelange/hugo-PaperMod/" rel="noopener" target="_blank">PaperMod</a>
    </span>
</footer>
<a href="#top" aria-label="go to top" title="Go to Top (Alt + G)" class="top-link" id="top-link" accesskey="g">
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentColor">
        <path d="M12 6H0l6-6z" />
    </svg>
</a>

<script>
    let menu = document.getElementById('menu');
    if (menu) {
        
        const scrollPosition = localStorage.getItem("menu-scroll-position");
        if (scrollPosition) {
            menu.scrollLeft = parseInt(scrollPosition, 10);
        }
        
        menu.onscroll = function () {
            localStorage.setItem("menu-scroll-position", menu.scrollLeft);
        }
    }

    document.querySelectorAll('a[href^="#"]').forEach(anchor => {
        anchor.addEventListener("click", function (e) {
            e.preventDefault();
            var id = this.getAttribute("href").substr(1);
            if (!window.matchMedia('(prefers-reduced-motion: reduce)').matches) {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({
                    behavior: "smooth"
                });
            } else {
                document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView();
            }
            if (id === "top") {
                history.replaceState(null, null, " ");
            } else {
                history.pushState(null, null, `#${id}`);
            }
        });
    });

</script>
<script>
    var mybutton = document.getElementById("top-link");
    window.onscroll = function () {
        if (document.body.scrollTop > 800 || document.documentElement.scrollTop > 800) {
            mybutton.style.visibility = "visible";
            mybutton.style.opacity = "1";
        } else {
            mybutton.style.visibility = "hidden";
            mybutton.style.opacity = "0";
        }
    };

</script>
</body>

</html>
